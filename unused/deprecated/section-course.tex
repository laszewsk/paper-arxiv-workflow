\subsection{MLCommons Deep-Learning based Course Curriculumn}

We can utilize the MLCommons effort to center a course curiculumn
around it. For this to work the course will be focussing on deep
learning while using examples from MLCommons benchmarks as well as
additional enhancements into other topics that may not be covered.

In contarst to other courses that may only focus on DL technologies
this course will have the requirement to utilize a significant
computational resources as for example available on many campuses as
part of an HPC or a national scale facility such as
Access. Alternatively Google Collab can be used.

The curriculum is devided into 6 sections that can be taught over a
semester in either a graduate or under graduate clas or a combination
therof.

\begin{enumerate}
  
\item{\bf Course overview and Introduction:} here the overview of the
  course is provided. Goals and expectations are explained. An
  introduction to deep learning is provided. This includes the history and
  applications of deep learning. A basic introduction to optimization
  technologies and neural networks is given. The connection between
  MLCommons Applications is presented.

\item{\bf Infrastructure and Benchmarking :} An overview of
  MLCommons-based deep learning applications and benchmarks are
  discussed. This will include a wide variety reaching from tiny
  devices to supercomputers and hyperscale clouds. Google Collab will
  be introduced. Practical topics such as using ssh and batch queues
  are discussed. An explicit effort is placed on using a code editor
  such as pyCHarm or VScode. Elementary software infrastructure is
  discussed while reviewing python concepts for functions, classes,
  and code packaging with pip. The use of GitHub is introduced.
  
\item{\bf Convolutional Neural Networks:} A deeper understanding is taught
  by focussing on convolutional neural networks (CNNs). The example of
  Mask R-CNN is explained.

\item{\bf Recurrent Neural Networks:} RNNs are taught and applications of
  RNNs are discussed. The RNN-T application focusing on speech
  recognition is presented and analyzed

\item{\bf Natural Language Processing:} As natural language processing has
  such a big impact on industry and academia additional lectures in that area
   are presented. This includes large language models,
  analyzing text, applications of NLP, language translation, and sentiment
  analysis.  Practical examples are introduced while looking at
  ChatGPT. From MLcommons the applications DLRM, BERT, RNN-T are
  discussed.

\item{\bf Project Presentations:} The last part of the class is
  focused on a project presentation that students can conduct in a
  team or individually. It should showcase an application and
  performance results on one or multiple HPC data systems, or include
  an improvement to an existing MLCommons benchmark. It is expected
  that the students write a high-quality project report.
  
 \end{enumerate}

Adaptations of this material are possible and can be adapted
accordingly. The semester-long project is accompanied by bi-weekly
practical mini-assignments showcasing selected results and
implementations of a particular topic.
